{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNR2wDzMeh/+7/0/Be34J/0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c5c6c3c4fd954f15986543769f575b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60a564db4c924ccd967dacdf1c313976",
              "IPY_MODEL_11594cce07414d0d872564a273844ed0",
              "IPY_MODEL_3a1b33262c734a5eb90991984f1aab47"
            ],
            "layout": "IPY_MODEL_3d85b2ca244f49889ed356ae95bdbffa"
          }
        },
        "60a564db4c924ccd967dacdf1c313976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e70814ff85b1449397a5a30d83570609",
            "placeholder": "​",
            "style": "IPY_MODEL_354b0db509bf43309ef3ffa1a8780dba",
            "value": "100%"
          }
        },
        "11594cce07414d0d872564a273844ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac0be8b78e4d47fcbf6beda0224f2513",
            "max": 4803584173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99334468dd434b7aaa6c9f0d206d1146",
            "value": 4803584173
          }
        },
        "3a1b33262c734a5eb90991984f1aab47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebe7bb95940b4b5a86c52597ca36749c",
            "placeholder": "​",
            "style": "IPY_MODEL_de57f353e41e4988afbccc568249b840",
            "value": " 4.47G/4.47G [00:25&lt;00:00, 233MB/s]"
          }
        },
        "3d85b2ca244f49889ed356ae95bdbffa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e70814ff85b1449397a5a30d83570609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "354b0db509bf43309ef3ffa1a8780dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac0be8b78e4d47fcbf6beda0224f2513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99334468dd434b7aaa6c9f0d206d1146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebe7bb95940b4b5a86c52597ca36749c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de57f353e41e4988afbccc568249b840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cmagliano/Proj/blob/main/ImageSearchOnE_CommerceSites.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform Image-Driven Reverse Image Search on E-Commerce Sites with ImageBind and Qdrant\n",
        "\n",
        "Author:Cláudia Magliano\n",
        "\n",
        "Date:14/07/2024\n",
        "\n"
      ],
      "metadata": {
        "id": "BfiuPc_FJQaS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**install the dependencies first to get started with the reverse product image search.**"
      ],
      "metadata": {
        "id": "ZxFZeKd2JNBF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wGQlNFKJCCM",
        "outputId": "2c3c4f83-17f5-4476-bb95-3215b1aba21e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.38.1-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qdrant-client\n",
            "  Downloading qdrant_client-1.10.1-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.6.14)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting altair<6.0,>=5.0 (from gradio)\n",
            "  Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==1.1.0 (from gradio)\n",
            "  Downloading gradio_client-1.1.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.4)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.5.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.1.0->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==1.1.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.64.1)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client)\n",
            "  Downloading grpcio_tools-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker<3.0.0,>=2.7.0 (from qdrant-client)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=5.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=5.0->gradio) (0.12.1)\n",
            "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-tools>=1.41.0->qdrant-client)\n",
            "  Downloading protobuf-5.27.2-cp38-abi3-manylinux2014_x86_64.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.3/309.3 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (67.7.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2<5,>=3 (from httpx>=0.24.1->gradio)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx>=0.24.1->gradio)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx>=0.24.1->gradio)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (0.19.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=43d8546a31cd3f1188603de62ecf69315a69b0243f354fb4ae98f795009b257d\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uvloop, tomlkit, semantic-version, ruff, python-multipart, python-dotenv, protobuf, portalocker, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hyperframe, httptools, hpack, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, httpcore, h2, grpcio-tools, email_validator, opendatasets, nvidia-cusolver-cu12, httpx, gradio-client, fastapi-cli, altair, sentence_transformers, qdrant-client, fastapi, gradio\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: altair\n",
            "    Found existing installation: altair 4.2.2\n",
            "    Uninstalling altair-4.2.2:\n",
            "      Successfully uninstalled altair-4.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-api-core 2.16.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-aiplatform 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.25.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-bigtable 2.24.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-functions 1.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-translate 3.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.27.2 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 altair-5.3.0 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.1 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.38.1 gradio-client-1.1.0 grpcio-tools-1.64.1 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 hyperframe-6.0.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 opendatasets-0.1.22 orjson-3.10.6 portalocker-2.10.1 protobuf-5.27.2 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 qdrant-client-1.10.1 ruff-0.5.2 semantic-version-2.10.0 sentence_transformers-3.0.1 starlette-0.37.2 tomlkit-0.12.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets gradio qdrant-client transformers sentence_transformers sentencepiece tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the Dataset**\n",
        "\n",
        "Using the opendatasets library, download the Kaggle dataset using your username and key. You can obtain them by visiting the Settings page on Kaggle. Click on “Access API Keys,” and a kaggle.json file will be downloaded. This file will contain your username and API key."
      ],
      "metadata": {
        "id": "xYT5TIsQKjO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/vikashrajluhaniwal/fashion-images\")\n",
        "#user: cvmagliano"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQooNbRLJHo9",
        "outputId": "30b55683-d6fd-4e04-d0cb-1efa7441b513"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: cvmagliano@gmail.com\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/vikashrajluhaniwal/fashion-images\n",
            "Downloading fashion-images.zip to ./fashion-images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335M/335M [00:11<00:00, 30.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Storing the images in a list so that we can easily access the images.**"
      ],
      "metadata": {
        "id": "BY6uHLd3MEA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http import models\n",
        "import tempfile\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_image_paths(directory):\n",
        "  # Initialize an empty list to store the image paths\n",
        "  image_paths = []\n",
        "  # Iterate through all files and directories within the given directory\n",
        "  for (root, dirs, files) in os.walk(directory):\n",
        "    for file in files:\n",
        "       # Check if the file has an image extension (e.g., .jpg, .png, .jpeg, etc.)\n",
        "      if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "         # Construct the full path to the image file\n",
        "         image_path = os.path.join(root, file)\n",
        "         # Append the image path to the list\n",
        "         image_paths.append(image_path)\n",
        "  return image_paths\n",
        "\n",
        "# Directory paths\n",
        "women_directory = './fashion-images/data/Footwear/Women/Images/images_with_product_ids/'\n",
        "men_directory = './fashion-images/data/Footwear/Men/Images/images_with_product_ids/'\n",
        "girls_directory = './fashion-images/data/Apparel/Girls/Images/images_with_product_ids/'\n",
        "boys_directory = './fashion-images/data/Apparel/Boys/Images/images_with_product_ids/'\n",
        "\n",
        "\n",
        "# Get image paths for different categories\n",
        "image_paths_Women = get_image_paths(women_directory)\n",
        "image_paths_Men = get_image_paths(men_directory)\n",
        "image_paths_Girls = get_image_paths(girls_directory)\n",
        "image_paths_Boys = get_image_paths(boys_directory)\n",
        "\n",
        "all_image_paths = []\n",
        "all_image_paths.append(image_paths_Boys)\n",
        "all_image_paths.append(image_paths_Girls)\n",
        "all_image_paths.append(image_paths_Men)\n",
        "all_image_paths.append(image_paths_Women)\n",
        "\n"
      ],
      "metadata": {
        "id": "zInohhGfKts8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initializing the Qdrant Vector DB**\n",
        "\n",
        "Initialize the Qdrant Client with in-memory storage. The collection name will be “imagebind_data” and we will be using cosine distance."
      ],
      "metadata": {
        "id": "pcdeex8IMbyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Qdrant client and load collection\n",
        "client = QdrantClient(\":memory:\")\n",
        "client.recreate_collection(collection_name = \"imagebind_data\",\n",
        "vectors_config = {\"image\": models.VectorParams( size = 1024, distance = models.Distance.COSINE ) } )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwKwtolcMUIn",
        "outputId": "0b31436d-e8dc-4e04-9e05-3c151b96c4f9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-58797df4bcef>:3: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
            "  client.recreate_collection(collection_name = \"imagebind_data\",\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image Embeddings with ImageBind**\n",
        "\n",
        "ImageBind is an innovative model developed by Meta AI’s FAIR Lab. This model is designed to learn a joint embedding across six different modalities: images, text, audio, depth, thermal, and IMU data. One of the key features of ImageBind is its ability to learn this joint embedding without requiring all combinations of paired data. It has been discovered that only image-paired data is necessary to bind the modalities together effectively. This unique capability allows ImageBind to leverage recent large-scale vision-language models and extend their zero-shot capabilities to new modalities simply by utilizing their natural pairing with images.\n",
        "\n",
        "mageBind will be used for creating embeddings, but before diving deep, first, we follow some steps required for installing ImageBind."
      ],
      "metadata": {
        "id": "fw65ScB8Mn_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/ImageBind.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Krdxy3JKl_nb",
        "outputId": "78cb50a2-cea5-4918-87f9-3e6e0f2f1870"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ImageBind'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 146 (delta 61), reused 48 (delta 39), pack-reused 47\u001b[K\n",
            "Receiving objects: 100% (146/146), 2.65 MiB | 26.55 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('./ImageBind')"
      ],
      "metadata": {
        "id": "wvS7dEtLNKLr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltQtdDXNOJaL",
        "outputId": "6d156f7c-0e1f-4b78-89d2-65f6d37720f5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorchvideo@ git+https://github.com/facebookresearch/pytorchvideo.git@28fe037d212663c6a24f373b94cc5d478c8c1a1d (from -r requirements.txt (line 4))\n",
            "  Cloning https://github.com/facebookresearch/pytorchvideo.git (to revision 28fe037d212663c6a24f373b94cc5d478c8c1a1d) to /tmp/pip-install-zkypez5r/pytorchvideo_f7220c7e94124a2d993c5105c20e1fd0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/pytorchvideo.git /tmp/pip-install-zkypez5r/pytorchvideo_f7220c7e94124a2d993c5105c20e1fd0\n",
            "  Running command git rev-parse -q --verify 'sha^28fe037d212663c6a24f373b94cc5d478c8c1a1d'\n",
            "  Running command git fetch -q https://github.com/facebookresearch/pytorchvideo.git 28fe037d212663c6a24f373b94cc5d478c8c1a1d\n",
            "  Running command git checkout -q 28fe037d212663c6a24f373b94cc5d478c8c1a1d\n",
            "  Resolved https://github.com/facebookresearch/pytorchvideo.git to commit 28fe037d212663c6a24f373b94cc5d478c8c1a1d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch==1.13.1 (from -r requirements.txt (line 1))\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.18.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.3.0+cu121)\n",
            "Collecting timm==0.6.7 (from -r requirements.txt (line 5))\n",
            "  Downloading timm-0.6.7-py3-none-any.whl (509 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.0/510.0 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy (from -r requirements.txt (line 6))\n",
            "  Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2024.5.15)\n",
            "Collecting einops (from -r requirements.txt (line 8))\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fvcore (from -r requirements.txt (line 9))\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting eva-decord==0.6.1 (from -r requirements.txt (line 10))\n",
            "  Downloading eva_decord-0.6.1-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting iopath (from -r requirements.txt (line 11))\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (3.7.1)\n",
            "Collecting types-regex (from -r requirements.txt (line 14))\n",
            "  Downloading types_regex-2024.5.15.20240519-py3-none-any.whl (5.6 kB)\n",
            "Collecting mayavi (from -r requirements.txt (line 15))\n",
            "  Downloading mayavi-4.8.2.tar.gz (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cartopy (from -r requirements.txt (line 16))\n",
            "  Downloading Cartopy-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1->-r requirements.txt (line 1)) (4.12.2)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->-r requirements.txt (line 1)) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->-r requirements.txt (line 1)) (0.43.0)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from -r requirements.txt (line 2))\n",
            "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.18.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.17.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (2.31.0)\n",
            "  Downloading torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.16.1-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m122.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchvision-0.14.1-cp310-cp310-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (9.4.0)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio (from -r requirements.txt (line 3))\n",
            "  Downloading torchaudio-2.3.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchaudio-2.2.2-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchaudio-2.2.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchaudio-2.2.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchaudio-2.1.2-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m117.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchaudio-2.1.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading torchaudio-2.1.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchaudio-2.0.2-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchaudio-2.0.1-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torchaudio-0.13.1-cp310-cp310-manylinux1_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting av (from pytorchvideo@ git+https://github.com/facebookresearch/pytorchvideo.git@28fe037d212663c6a24f373b94cc5d478c8c1a1d->-r requirements.txt (line 4))\n",
            "  Downloading av-12.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parameterized (from pytorchvideo@ git+https://github.com/facebookresearch/pytorchvideo.git@28fe037d212663c6a24f373b94cc5d478c8c1a1d->-r requirements.txt (line 4))\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pytorchvideo@ git+https://github.com/facebookresearch/pytorchvideo.git@28fe037d212663c6a24f373b94cc5d478c8c1a1d->-r requirements.txt (line 4)) (3.3)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements.txt (line 6)) (0.2.13)\n",
            "Collecting yacs>=0.1.6 (from fvcore->-r requirements.txt (line 9))\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->-r requirements.txt (line 9)) (6.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore->-r requirements.txt (line 9)) (4.66.4)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->-r requirements.txt (line 9)) (2.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore->-r requirements.txt (line 9)) (0.9.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath->-r requirements.txt (line 11)) (2.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 13)) (2.8.2)\n",
            "Collecting apptools (from mayavi->-r requirements.txt (line 15))\n",
            "  Downloading apptools-5.3.0-py3-none-any.whl (230 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.0/230.0 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting envisage (from mayavi->-r requirements.txt (line 15))\n",
            "  Downloading envisage-7.0.3-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.9/268.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyface>=6.1.1 (from mayavi->-r requirements.txt (line 15))\n",
            "  Downloading pyface-8.0.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from mayavi->-r requirements.txt (line 15)) (2.16.1)\n",
            "Collecting traits>=6.0.0 (from mayavi->-r requirements.txt (line 15))\n",
            "  Downloading traits-6.4.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traitsui>=7.0.0 (from mayavi->-r requirements.txt (line 15))\n",
            "  Downloading traitsui-8.0.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting vtk (from mayavi->-r requirements.txt (line 15))\n",
            "  Using cached vtk-9.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (92.1 MB)\n",
            "Requirement already satisfied: shapely>=1.7 in /usr/local/lib/python3.10/dist-packages (from cartopy->-r requirements.txt (line 16)) (2.0.4)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.10/dist-packages (from cartopy->-r requirements.txt (line 16)) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from cartopy->-r requirements.txt (line 16)) (3.6.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyproj>=3.3.1->cartopy->-r requirements.txt (line 16)) (2024.7.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 13)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r requirements.txt (line 2)) (2.0.7)\n",
            "Building wheels for collected packages: pytorchvideo, fvcore, iopath, mayavi\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=211198 sha256=35b15884de14ec13de5fd3c03fdf8e0c21391e9b20200dd9428c43b7a7417a30\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/a0/a9/b2f1582cd6198b0425b645bdcce413a15f58d9cc3beee721d0\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=d5d04188365bf12e48a9610baf2d67caef887146c24170fbefe4c52f428b4357\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=b84d651e1296c463f29d63951fd009fe4fcb3f442ea79a6bd18cb2872c06c96d\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "  Building wheel for mayavi (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mayavi: filename=mayavi-4.8.2-cp310-cp310-linux_x86_64.whl size=16762470 sha256=fd262d0aa11dfae5febbe540fa9f38e5e324a1dfc98798373c319e9355afe63e\n",
            "  Stored in directory: /root/.cache/pip/wheels/60/52/8c/d16aeced951729965d3a787b59424bfc235372fafd1130c56e\n",
            "Successfully built pytorchvideo fvcore iopath mayavi\n",
            "Installing collected packages: yacs, types-regex, traits, parameterized, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, iopath, ftfy, eva-decord, einops, av, pyface, nvidia-cudnn-cu11, fvcore, apptools, vtk, traitsui, torch, pytorchvideo, cartopy, torchvision, torchaudio, envisage, timm, mayavi\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.0+cu121\n",
            "    Uninstalling torch-2.3.0+cu121:\n",
            "      Successfully uninstalled torch-2.3.0+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.18.0+cu121\n",
            "    Uninstalling torchvision-0.18.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.18.0+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.3.0+cu121\n",
            "    Uninstalling torchaudio-2.3.0+cu121:\n",
            "      Successfully uninstalled torchaudio-2.3.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed apptools-5.3.0 av-12.2.0 cartopy-0.23.0 einops-0.8.0 envisage-7.0.3 eva-decord-0.6.1 ftfy-6.2.0 fvcore-0.1.5.post20221221 iopath-0.1.10 mayavi-4.8.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 parameterized-0.9.0 pyface-8.0.0 pytorchvideo-0.1.5 timm-0.6.7 torch-1.13.1 torchaudio-0.13.1 torchvision-0.14.1 traits-6.4.3 traitsui-8.0.0 types-regex-2024.5.15.20240519 vtk-9.3.1 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the model.**"
      ],
      "metadata": {
        "id": "fUzGsVFBO_NT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"./ImageBind/\")\n",
        "device = \"cuda\"\n",
        "import imagebind\n",
        "from imagebind.models import imagebind_model\n",
        "model = imagebind_model.imagebind_huge(pretrained=True)\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c5c6c3c4fd954f15986543769f575b2b",
            "60a564db4c924ccd967dacdf1c313976",
            "11594cce07414d0d872564a273844ed0",
            "3a1b33262c734a5eb90991984f1aab47",
            "3d85b2ca244f49889ed356ae95bdbffa",
            "e70814ff85b1449397a5a30d83570609",
            "354b0db509bf43309ef3ffa1a8780dba",
            "ac0be8b78e4d47fcbf6beda0224f2513",
            "99334468dd434b7aaa6c9f0d206d1146",
            "ebe7bb95940b4b5a86c52597ca36749c",
            "de57f353e41e4988afbccc568249b840"
          ]
        },
        "id": "4rMP8V38O59k",
        "outputId": "b748297b-e122-44ec-fac5-038bc6d70b92"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading imagebind weights to .checkpoints/imagebind_huge.pth ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/4.47G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5c6c3c4fd954f15986543769f575b2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageBindModel(\n",
              "  (modality_preprocessors): ModuleDict(\n",
              "    (vision): RGBDTPreprocessor(\n",
              "      (cls_token): tensor((1, 1, 1280), requires_grad=True)\n",
              "      \n",
              "      (rgbt_stem): PatchEmbedGeneric(\n",
              "        (proj): Sequential(\n",
              "          (0): PadIm2Video()\n",
              "          (1): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)\n",
              "        )\n",
              "      )\n",
              "      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
              "        (pos_embed): tensor((1, 257, 1280), requires_grad=True)\n",
              "        \n",
              "      )\n",
              "    )\n",
              "    (text): TextPreprocessor(\n",
              "      (pos_embed): tensor((1, 77, 1024), requires_grad=True)\n",
              "      (mask): tensor((77, 77), requires_grad=False)\n",
              "      \n",
              "      (token_embedding): Embedding(49408, 1024)\n",
              "    )\n",
              "    (audio): AudioPreprocessor(\n",
              "      (cls_token): tensor((1, 1, 768), requires_grad=True)\n",
              "      \n",
              "      (rgbt_stem): PatchEmbedGeneric(\n",
              "        (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10), bias=False)\n",
              "        (norm_layer): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
              "        (pos_embed): tensor((1, 229, 768), requires_grad=True)\n",
              "        \n",
              "      )\n",
              "    )\n",
              "    (depth): RGBDTPreprocessor(\n",
              "      (cls_token): tensor((1, 1, 384), requires_grad=True)\n",
              "      \n",
              "      (depth_stem): PatchEmbedGeneric(\n",
              "        (proj): Conv2d(1, 384, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
              "        (norm_layer): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
              "        (pos_embed): tensor((1, 197, 384), requires_grad=True)\n",
              "        \n",
              "      )\n",
              "    )\n",
              "    (thermal): ThermalPreprocessor(\n",
              "      (cls_token): tensor((1, 1, 768), requires_grad=True)\n",
              "      \n",
              "      (rgbt_stem): PatchEmbedGeneric(\n",
              "        (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
              "        (norm_layer): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(\n",
              "        (pos_embed): tensor((1, 197, 768), requires_grad=True)\n",
              "        \n",
              "      )\n",
              "    )\n",
              "    (imu): IMUPreprocessor(\n",
              "      (pos_embed): tensor((1, 251, 512), requires_grad=True)\n",
              "      (cls_token): tensor((1, 1, 512), requires_grad=True)\n",
              "      \n",
              "      (imu_stem): PatchEmbedGeneric(\n",
              "        (proj): Linear(in_features=48, out_features=512, bias=False)\n",
              "        (norm_layer): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (modality_trunks): ModuleDict(\n",
              "    (vision): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (12): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (13): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (14): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (15): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (16): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (17): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (18): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (19): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (20): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (21): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (22): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (23): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (24): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (25): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (26): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (27): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (28): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (29): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (30): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (31): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "    (text): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): Identity()\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (12): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (13): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (14): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (15): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (16): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (17): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (18): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (19): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (20): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (21): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (22): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (23): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "    (audio): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): Identity()\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.009)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.018)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.027)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.036)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.045)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.055)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.064)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.073)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.082)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.091)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.100)\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "    (depth): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): Identity()\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "    (thermal): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): Identity()\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (6): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (7): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (8): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (9): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (10): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (11): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "    (imu): SimpleTransformer(\n",
              "      (pre_transformer_layer): Sequential(\n",
              "        (0): Identity()\n",
              "        (1): EinOpsRearrange()\n",
              "      )\n",
              "      (blocks): Sequential(\n",
              "        (0): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.140)\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.280)\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.420)\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.560)\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BlockWithMasking(\n",
              "          (attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (drop_path): DropPath(drop_prob=0.700)\n",
              "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (act): GELU(approximate='none')\n",
              "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (post_transformer_layer): EinOpsRearrange()\n",
              "    )\n",
              "  )\n",
              "  (modality_heads): ModuleDict(\n",
              "    (vision): Sequential(\n",
              "      (0): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): SelectElement()\n",
              "      (2): Linear(in_features=1280, out_features=1024, bias=False)\n",
              "    )\n",
              "    (text): SelectEOSAndProject(\n",
              "      (proj): Sequential(\n",
              "        (0): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "        (1): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "      )\n",
              "    )\n",
              "    (audio): Sequential(\n",
              "      (0): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): SelectElement()\n",
              "      (2): Linear(in_features=768, out_features=1024, bias=False)\n",
              "    )\n",
              "    (depth): Sequential(\n",
              "      (0): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): SelectElement()\n",
              "      (2): Linear(in_features=384, out_features=1024, bias=False)\n",
              "    )\n",
              "    (thermal): Sequential(\n",
              "      (0): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): SelectElement()\n",
              "      (2): Linear(in_features=768, out_features=1024, bias=False)\n",
              "    )\n",
              "    (imu): Sequential(\n",
              "      (0): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
              "      (1): SelectElement()\n",
              "      (2): Dropout(p=0.5, inplace=False)\n",
              "      (3): Linear(in_features=512, out_features=1024, bias=False)\n",
              "    )\n",
              "  )\n",
              "  (modality_postprocessors): ModuleDict(\n",
              "    (vision): Normalize()\n",
              "    (text): Sequential(\n",
              "      (0): Normalize()\n",
              "      (1): LearnableLogitScaling(logit_scale_init=14.285714285714285,learnable=True, max_logit_scale=100)\n",
              "    )\n",
              "    (audio): Sequential(\n",
              "      (0): Normalize()\n",
              "      (1): LearnableLogitScaling(logit_scale_init=20.0,learnable=False, max_logit_scale=100)\n",
              "    )\n",
              "    (depth): Sequential(\n",
              "      (0): Normalize()\n",
              "      (1): LearnableLogitScaling(logit_scale_init=5.0,learnable=False, max_logit_scale=100)\n",
              "    )\n",
              "    (thermal): Sequential(\n",
              "      (0): Normalize()\n",
              "      (1): LearnableLogitScaling(logit_scale_init=10.0,learnable=False, max_logit_scale=100)\n",
              "    )\n",
              "    (imu): Sequential(\n",
              "      (0): Normalize()\n",
              "      (1): LearnableLogitScaling(logit_scale_init=5.0,learnable=False, max_logit_scale=100)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Initializing the model, we will now create embeddings.**"
      ],
      "metadata": {
        "id": "9a3vo5YZPpRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imagebind.models.imagebind_model import ModalityType\n",
        "from imagebind import data\n",
        "import torch\n",
        "embeddings_list = []\n",
        "\n",
        "for image_paths in [image_paths_Boys, image_paths_Girls, image_paths_Men, image_paths_Women]:\n",
        "  inputs = {ModalityType.VISION: data.load_and_transform_vision_data(image_paths, device)}\n",
        "  with torch.no_grad():\n",
        "    embeddings = model(inputs)\n",
        "  embeddings_list.append(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "NbQVB0tKPkMW",
        "outputId": "aa3f4eb6-2bfc-47d4-e8f4-2a277ed2ffb1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './fashion-images/data/Apparel/Boys/Images/images_with_product_ids/35877.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9f07f753435f>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_paths\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage_paths_Boys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_paths_Girls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_paths_Men\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_paths_Women\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mModalityType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVISION\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_and_transform_vision_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ImageBind/imagebind/data.py\u001b[0m in \u001b[0;36mload_and_transform_vision_data\u001b[0;34m(image_paths, device)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfopen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfopen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './fashion-images/data/Apparel/Boys/Images/images_with_product_ids/35877.jpg'"
          ]
        }
      ]
    }
  ]
}